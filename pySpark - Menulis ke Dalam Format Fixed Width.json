{"paragraphs":[{"text":"%md\nPada Spark Dataframe, kita data mengeksport file berbentuk csv secara default. Ada beberapa kondisi, kita harus mengeksport file ke dalam format fixed-width. Contohnya: \n\n```\n  col1    col2     col3          col4\n+------+--------+-------+-------------------+\n1              1     4.02000-07-30 14:45:03\n1              3     4.02000-07-30 14:20:47 \n1              6     4.02000-07-30 14:37:04 \n1             47     5.02000-07-30 15:03:35 \n10            50     5.02000-07-30 14:48:51\n```","user":"yava","dateUpdated":"2020-05-28T14:34:13-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false,"completionKey":"TAB"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Pada Spark Dataframe, kita data mengeksport file berbentuk csv secara default. Ada beberapa kondisi, kita harus mengeksport file ke dalam format fixed-width. Contohnya: </p>\n<pre><code>  col1    col2     col3          col4\n+------+--------+-------+-------------------+\n1              1     4.02000-07-30 14:45:03\n1              3     4.02000-07-30 14:20:47 \n1              6     4.02000-07-30 14:37:04 \n1             47     5.02000-07-30 15:03:35 \n10            50     5.02000-07-30 14:48:51\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1590690016182_1763143794","id":"20200528-142016_2067569390","dateCreated":"2020-05-28T14:20:16-0400","dateStarted":"2020-05-28T14:34:13-0400","dateFinished":"2020-05-28T14:34:13-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2712"},{"text":"%spark.pyspark\nprint(\"Spark version : \" + spark.version)","user":"yava","dateUpdated":"2020-05-28T12:53:21-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Spark version : 2.3.2\n"}]},"apps":[],"jobName":"paragraph_1590684746173_-2065576654","id":"20200528-125226_234848291","dateCreated":"2020-05-28T12:52:26-0400","dateStarted":"2020-05-28T12:53:21-0400","dateFinished":"2020-05-28T12:54:34-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2713"},{"title":"Buat data","text":"%spark.pyspark\n\ndata = [\n    (1, 1, 4.0, \"2000-07-30 14:45:03\"),\n    (1, 3, 4.0, \"2000-07-30 14:20:47\"),\n    (1, 6, 4.0, \"2000-07-30 14:37:04\"),\n    (1, 47, 5.0, \"2000-07-30 15:03:35\"),\n    (10, 50, 5.0, \"2000-07-30 14:48:51\")\n]","user":"yava","dateUpdated":"2020-05-28T14:26:50-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python","editorHide":false,"tableHide":true,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590684801938_1287161163","id":"20200528-125321_520070815","dateCreated":"2020-05-28T12:53:21-0400","dateStarted":"2020-05-28T13:44:30-0400","dateFinished":"2020-05-28T13:44:30-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2714"},{"title":"Baca data ke dalam format Dataframe","text":"%spark.pyspark\n\ndf = spark.createDataFrame(data, [\"userId\", \"movieId\", \"rating\", \"time_stamp\"])\ndf.show()","user":"yava","dateUpdated":"2020-05-28T23:41:27-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+-------+------+-------------------+\n|userId|movieId|rating|         time_stamp|\n+------+-------+------+-------------------+\n|     1|      1|   4.0|2000-07-30 14:45:03|\n|     1|      3|   4.0|2000-07-30 14:20:47|\n|     1|      6|   4.0|2000-07-30 14:37:04|\n|     1|     47|   5.0|2000-07-30 15:03:35|\n|    10|     50|   5.0|2000-07-30 14:48:51|\n+------+-------+------+-------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1590685299252_-1590993900","id":"20200528-130139_1024694650","dateCreated":"2020-05-28T13:01:39-0400","dateStarted":"2020-05-28T14:19:13-0400","dateFinished":"2020-05-28T14:19:14-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2715"},{"text":"%spark.pyspark\n\nfrom pyspark.sql.functions import concat, format_string, rpad, lpad\n","user":"yava","dateUpdated":"2020-05-28T14:19:17-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590685425819_-25277553","id":"20200528-130345_732638769","dateCreated":"2020-05-28T13:03:45-0400","dateStarted":"2020-05-28T14:19:17-0400","dateFinished":"2020-05-28T14:19:17-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2716"},{"title":"Tampilkan Dataframe","text":"%spark.pyspark\n\ndf.show(truncate=False)","user":"yava","dateUpdated":"2020-05-28T14:27:58-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+-------+------+-------------------+\n|userId|movieId|rating|time_stamp         |\n+------+-------+------+-------------------+\n|1     |1      |4.0   |2000-07-30 14:45:03|\n|1     |3      |4.0   |2000-07-30 14:20:47|\n|1     |6      |4.0   |2000-07-30 14:37:04|\n|1     |47     |5.0   |2000-07-30 15:03:35|\n|10    |50     |5.0   |2000-07-30 14:48:51|\n+------+-------+------+-------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1590685521427_10937428","id":"20200528-130521_201506178","dateCreated":"2020-05-28T13:05:21-0400","dateStarted":"2020-05-28T14:27:58-0400","dateFinished":"2020-05-28T14:27:59-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2717"},{"title":"Buat kolom baru dengan menggunakan concat, lpad dan rpad","text":"%spark.pyspark\nresult = df.select( concat(\n          rpad(df.userId, 8, \" \"),\n          lpad(df.movieId, 8, \" \"),\n          lpad(df.rating, 8,\" \"),\n          rpad(df.time_stamp, 20,\" \") ).alias(\"new\"))\n#   .show(truncate=False)\n# field pertama dibuat rpad karena akan ditrim klo disave ","user":"yava","dateUpdated":"2020-05-28T14:28:36-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"title":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590685588843_-181500606","id":"20200528-130628_986977237","dateCreated":"2020-05-28T13:06:28-0400","dateStarted":"2020-05-28T14:19:37-0400","dateFinished":"2020-05-28T14:19:37-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2718"},{"title":"Tampilkan Dataframe yang baru","text":"%spark.pyspark\n\nresult.show(truncate=False)","user":"yava","dateUpdated":"2020-05-28T14:28:57-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------------------------------+\n|new                                         |\n+--------------------------------------------+\n|1              1     4.02000-07-30 14:45:03 |\n|1              3     4.02000-07-30 14:20:47 |\n|1              6     4.02000-07-30 14:37:04 |\n|1             47     5.02000-07-30 15:03:35 |\n|10            50     5.02000-07-30 14:48:51 |\n+--------------------------------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1590687009242_-440414373","id":"20200528-133009_201741045","dateCreated":"2020-05-28T13:30:09-0400","dateStarted":"2020-05-28T14:19:40-0400","dateFinished":"2020-05-28T14:19:40-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2719"},{"title":"Simpan ke dalam file di local server","text":"%spark.pyspark\nresult.toPandas().to_csv(\"result.txt\", header=False, index=False)","user":"yava","dateUpdated":"2020-05-28T14:29:31-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590687050054_1826982543","id":"20200528-133050_320936914","dateCreated":"2020-05-28T13:30:50-0400","dateStarted":"2020-05-28T13:52:42-0400","dateFinished":"2020-05-28T13:52:42-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2720"},{"text":"%sh\n\nls -lah","user":"yava","dateUpdated":"2020-05-28T13:45:26-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"total 2.4G\ndrwx------  12 yava yava 4.0K May 28 13:45 .\ndrwxr-xr-x. 14 root root  165 Apr  2 10:10 ..\n-rw-------   1 yava yava 9.8K May 26 15:44 .bash_history\n-rw-r--r--   1 yava yava   18 Aug  8  2019 .bash_logout\n-rw-r--r--   1 yava yava  193 Aug  8  2019 .bash_profile\n-rw-r--r--   1 yava yava  706 Apr 28 15:22 .bashrc\ndrwxr-xr-x   2 yava yava   21 Apr  2 10:25 .beeline\ndrwxr-xr-x   3 yava yava   24 May  8 03:51 .cache\ndrwxr-xr-x   2 yava yava   30 Apr 28 15:20 .conda\n-rw-r--r--   1 yava yava   26 Apr 28 15:23 .condarc\ndrwxr-xr-x   3 yava yava   24 May  8 03:51 .config\ndrwxr-xr-x   3 yava yava  161 May 12 13:18 dataset\ndrwxr-xr-x   2 yava yava    6 Apr 28 15:52 .empty\n-rw-r--r--   1 yava yava  247 Apr 28 06:27 .hivehistory\ndrwxr-xr-x  16 yava yava  240 Apr 28 15:22 miniconda2\n-rwxr-xr-x   1 yava yava  47M Apr 28 15:18 Miniconda2-latest-Linux-x86_64.sh\n-rw-r--r--   1 yava yava  225 May 28 13:45 result.txt\n-rw-r--r--   1 yava yava    0 May  8 03:50 .scala_history\ndrwx------   2 yava yava   25 Apr 28 15:17 .ssh\n-rw-r--r--   1 yava yava  225 May 28 13:33 test.txt\n-rw-r--r--   1 yava yava  97K May 11 11:21 time_series_covid19_confirmed_global.csv\n-rw-r--r--   1 yava yava  74K May 11 11:23 time_series_covid19_deaths_global.csv\n-rw-r--r--   1 yava yava  82K May 11 11:23 time_series_covid19_recovered_global.csv\ndrwxr-xr-x  12 yava yava  240 May 28 12:47 zeppelin\ndrwxr-xr-x   8 yava yava  167 Sep 25  2019 zeppelin-0.8.2-bin-all\n-rw-r--r--   1 yava yava 953M Sep 26  2019 zeppelin-0.8.2-bin-all.tgz\n-rw-r--r--   1 yava yava 720M May  2 13:40 zeppelin-0.8.2-bin-yava-2005.03.00.tgz\n-rw-r--r--   1 yava yava 725M May  2 11:53 zeppelin.gz\n"}]},"apps":[],"jobName":"paragraph_1590687084947_540144448","id":"20200528-133124_885335891","dateCreated":"2020-05-28T13:31:24-0400","dateStarted":"2020-05-28T13:45:26-0400","dateFinished":"2020-05-28T13:45:26-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2721"},{"text":"%sh\ncat result.txt","user":"yava","dateUpdated":"2020-05-28T13:52:46-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1              1     4.02000-07-30 14:45:03 \n1              3     4.02000-07-30 14:20:47 \n1              6     4.02000-07-30 14:37:04 \n1             47     5.02000-07-30 15:03:35 \n10            50     5.02000-07-30 14:48:51 \n"}]},"apps":[],"jobName":"paragraph_1590687109822_-1377967039","id":"20200528-133149_1015207161","dateCreated":"2020-05-28T13:31:49-0400","dateStarted":"2020-05-28T13:52:46-0400","dateFinished":"2020-05-28T13:52:46-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2722"},{"text":"%spark.pyspark\nresult.write.save('/user/yava/result', format='csv', mode='overwrite')\n\n# mode: \"overwrite\" \n#       \"append\" \n#       \"error\" or \"errorifexists\" (default)\n#       \"ignore\" --> if data already exists, the save operation is expected not to save","user":"yava","dateUpdated":"2020-05-28T13:52:55-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590687516655_1473136316","id":"20200528-133836_1117978156","dateCreated":"2020-05-28T13:38:36-0400","dateStarted":"2020-05-28T13:52:55-0400","dateFinished":"2020-05-28T13:52:56-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2723"},{"text":"%sh\nhdfs dfs -ls /user/yava/result","user":"yava","dateUpdated":"2020-05-28T13:52:58-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nFound 3 items\n-rw-r--r--   3 yava hdfs          0 2020-05-28 13:52 /user/yava/result/_SUCCESS\n-rw-r--r--   3 yava hdfs         88 2020-05-28 13:52 /user/yava/result/part-00000-bfccc28e-99c7-4ff7-bd73-462d10ce9e72-c000.csv\n-rw-r--r--   3 yava hdfs        132 2020-05-28 13:52 /user/yava/result/part-00001-bfccc28e-99c7-4ff7-bd73-462d10ce9e72-c000.csv\n"}]},"apps":[],"jobName":"paragraph_1590687615362_374549243","id":"20200528-134015_1836522894","dateCreated":"2020-05-28T13:40:15-0400","dateStarted":"2020-05-28T13:52:58-0400","dateFinished":"2020-05-28T13:53:03-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2724"},{"text":"%sh\nhdfs dfs -cat result/part-00000-bfccc28e-99c7-4ff7-bd73-462d10ce9e72-c000.csv","user":"yava","dateUpdated":"2020-05-28T13:53:15-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n1              1     4.02000-07-30 14:45:03\n1              3     4.02000-07-30 14:20:47\n"}]},"apps":[],"jobName":"paragraph_1590687678892_1531479337","id":"20200528-134118_1671504480","dateCreated":"2020-05-28T13:41:18-0400","dateStarted":"2020-05-28T13:53:15-0400","dateFinished":"2020-05-28T13:53:20-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2725"},{"text":"%sh\nhdfs dfs -cat result/part-00001-bfccc28e-99c7-4ff7-bd73-462d10ce9e72-c000.csv","user":"yava","dateUpdated":"2020-05-28T13:53:30-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n1              6     4.02000-07-30 14:37:04\n1             47     5.02000-07-30 15:03:35\n10            50     5.02000-07-30 14:48:51\n"}]},"apps":[],"jobName":"paragraph_1590687743402_-1135508802","id":"20200528-134223_2045329774","dateCreated":"2020-05-28T13:42:23-0400","dateStarted":"2020-05-28T13:53:30-0400","dateFinished":"2020-05-28T13:53:34-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2726"},{"text":"%spark.pyspark\nresult.coalesce(1) \\\n      .write \\\n      .option(\"header\",\"false\") \\\n      .mode(\"overwrite\") \\\n      .csv(\"result-coal\")","user":"yava","dateUpdated":"2020-05-28T13:58:46-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590685931175_90199528","id":"20200528-131211_2083660628","dateCreated":"2020-05-28T13:12:11-0400","dateStarted":"2020-05-28T13:58:44-0400","dateFinished":"2020-05-28T13:58:45-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2727"},{"text":"%sh\nhdfs dfs -ls result-coal","user":"yava","dateUpdated":"2020-05-28T13:58:50-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false,"completionKey":"TAB"},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nFound 2 items\n-rw-r--r--   3 yava hdfs          0 2020-05-28 13:58 result-coal/_SUCCESS\n-rw-r--r--   3 yava hdfs        220 2020-05-28 13:58 result-coal/part-00000-d9f2565b-508f-4946-9b21-9bce1611e37e-c000.csv\n"}]},"apps":[],"jobName":"paragraph_1590688628529_1208959315","id":"20200528-135708_612586839","dateCreated":"2020-05-28T13:57:08-0400","dateStarted":"2020-05-28T13:58:50-0400","dateFinished":"2020-05-28T13:58:54-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2728"},{"text":"%sh\nhdfs dfs -cat result-coal/part-00000-d9f2565b-508f-4946-9b21-9bce1611e37e-c000.csv","user":"yava","dateUpdated":"2020-05-28T13:59:04-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n1              1     4.02000-07-30 14:45:03\n1              3     4.02000-07-30 14:20:47\n1              6     4.02000-07-30 14:37:04\n1             47     5.02000-07-30 15:03:35\n10            50     5.02000-07-30 14:48:51\n"}]},"apps":[],"jobName":"paragraph_1590688685218_-870959230","id":"20200528-135805_375024303","dateCreated":"2020-05-28T13:58:05-0400","dateStarted":"2020-05-28T13:59:04-0400","dateFinished":"2020-05-28T13:59:09-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2729"},{"text":"%spark.pyspark\nresult.repartition(1).write.csv(path=\"result-repart\", mode=\"overwrite\", header=\"false\")","user":"yava","dateUpdated":"2020-05-28T14:00:17-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1590686742326_-1020019789","id":"20200528-132542_1923268196","dateCreated":"2020-05-28T13:25:42-0400","dateStarted":"2020-05-28T14:00:17-0400","dateFinished":"2020-05-28T14:00:18-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2730"},{"text":"%sh\nhdfs dfs -ls result-repart\n","user":"yava","dateUpdated":"2020-05-28T14:00:40-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false,"completionKey":"TAB"},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nFound 2 items\n-rw-r--r--   3 yava hdfs          0 2020-05-28 14:00 result-repart/_SUCCESS\n-rw-r--r--   3 yava hdfs        220 2020-05-28 14:00 result-repart/part-00000-beb3fd67-f166-4b22-8e68-f856fb66e2c3-c000.csv\n"}]},"apps":[],"jobName":"paragraph_1590688829393_-12555957","id":"20200528-140029_304762462","dateCreated":"2020-05-28T14:00:29-0400","dateStarted":"2020-05-28T14:00:40-0400","dateFinished":"2020-05-28T14:00:45-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2731"},{"text":"%sh\nhdfs dfs -cat result-repart/part-00000-beb3fd67-f166-4b22-8e68-f856fb66e2c3-c000.csv","user":"yava","dateUpdated":"2020-05-28T14:01:02-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/yava/3.0.0.0-0000/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n1              1     4.02000-07-30 14:45:03\n1              3     4.02000-07-30 14:20:47\n1              6     4.02000-07-30 14:37:04\n1             47     5.02000-07-30 15:03:35\n10            50     5.02000-07-30 14:48:51\n"}]},"apps":[],"jobName":"paragraph_1590688854407_890275240","id":"20200528-140054_1329918394","dateCreated":"2020-05-28T14:00:54-0400","dateStarted":"2020-05-28T14:01:02-0400","dateFinished":"2020-05-28T14:01:07-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2732"},{"text":"","user":"yava","dateUpdated":"2020-05-28T14:04:10-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590689029017_1854273999","id":"20200528-140349_1752093986","dateCreated":"2020-05-28T14:03:49-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2733"},{"text":"","user":"yava","dateUpdated":"2020-05-28T14:00:15-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false,"completionKey":"TAB"},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590686862009_192164891","id":"20200528-132742_728763742","dateCreated":"2020-05-28T13:27:42-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2734"},{"text":"## Difference between coalesce and repartition\n\ncoalesce uses existing partitions to minimize the amount of data that's shuffled. repartition creates new partitions and does a full shuffle. coalesce results in partitions with different amounts of data (sometimes partitions that have much different sizes) and repartition results in roughly equal sized partitions.\n\nIs coalesce or repartition faster?\n\ncoalesce may run faster than repartition, but unequal sized partitions are generally slower to work with than equal sized partitions. You'll usually need to repartition datasets after filtering a large data set. I've found repartition to be faster overall because Spark is built to work with equal sized partitions.\n\nLocal mode: Spark partitions data into the number of CPU cores\nHDFS cluster, by default, Spark creates one Partition for each block of the file\n\nsource: \nhttps://stackoverflow.com/questions/31610971/spark-repartition-vs-coalesce\nhttps://sparkbyexamples.com/spark/spark-repartition-vs-coalesce/","user":"yava","dateUpdated":"2020-05-28T14:13:56-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Difference between coalesce and repartition</h2>\n<p>coalesce uses existing partitions to minimize the amount of data that&rsquo;s shuffled. repartition creates new partitions and does a full shuffle. coalesce results in partitions with different amounts of data (sometimes partitions that have much different sizes) and repartition results in roughly equal sized partitions.</p>\n<p>Is coalesce or repartition faster?</p>\n<p>coalesce may run faster than repartition, but unequal sized partitions are generally slower to work with than equal sized partitions. You&rsquo;ll usually need to repartition datasets after filtering a large data set. I&rsquo;ve found repartition to be faster overall because Spark is built to work with equal sized partitions.</p>\n<p>Local mode: Spark partitions data into the number of CPU cores<br/>HDFS cluster, by default, Spark creates one Partition for each block of the file</p>\n<p>source:<br/><a href=\"https://stackoverflow.com/questions/31610971/spark-repartition-vs-coalesce\">https://stackoverflow.com/questions/31610971/spark-repartition-vs-coalesce</a><br/><a href=\"https://sparkbyexamples.com/spark/spark-repartition-vs-coalesce/\">https://sparkbyexamples.com/spark/spark-repartition-vs-coalesce/</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1590689235524_2752002","id":"20200528-140715_693778395","dateCreated":"2020-05-28T14:07:15-0400","dateStarted":"2020-05-28T14:13:56-0400","dateFinished":"2020-05-28T14:13:56-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2735"},{"text":"%spark.pyspark\n\nresult.rdd.getNumPartitions()","user":"yava","dateUpdated":"2020-05-28T14:09:25-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2\n"}]},"apps":[],"jobName":"paragraph_1590689034242_-680666367","id":"20200528-140354_2114645992","dateCreated":"2020-05-28T14:03:54-0400","dateStarted":"2020-05-28T14:09:25-0400","dateFinished":"2020-05-28T14:09:25-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2736"},{"text":"%spark.pyspark\n","user":"yava","dateUpdated":"2020-05-28T14:10:53-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionSupport":true,"completionKey":"TAB"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1590689453239_1965606105","id":"20200528-141053_1062720828","dateCreated":"2020-05-28T14:10:53-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2737"}],"name":"Ngulik Big Data/pySpark - Menulis ke Dalam Format Fixed Width","id":"2F8T6ZNHB","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:yava:":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}